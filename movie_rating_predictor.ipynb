{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model to Predict Movie Ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS, ALSModel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from cold_start import get_cold_start_rating\n",
    "import pyspark\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a SparkSession object\n",
    "spark = pyspark(.sql\n",
    "                .SparkSession\n",
    "                .builder\n",
    "                .master(\"local[*]\")\n",
    "                .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ratings json file into spark dataframe\n",
    "\n",
    "movie_ratings = spark.read.json('data/ratings.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movie_id: long (nullable = true)\n",
      " |-- rating: long (nullable = true)\n",
      " |-- timestamp: double (nullable = true)\n",
      " |-- user_id: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check schema\n",
    "movie_ratings.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 719949 entries, 0 to 719948\n",
      "Data columns (total 4 columns):\n",
      "movie_id     719949 non-null int64\n",
      "rating       719949 non-null int64\n",
      "timestamp    719949 non-null float64\n",
      "user_id      719949 non-null int64\n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 22.0 MB\n"
     ]
    }
   ],
   "source": [
    "# cast to Pandas dataframe to turn timestamp data to datetime and check nulls. \n",
    "\n",
    "movies_df = movie_ratings.select('*').toPandas()\n",
    "movies_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000    719949\n",
       "Name: timestamp, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attempt to change timestamp object to years, all years are 2000\n",
    "\n",
    "date = pd.to_datetime(movies_df['timestamp'], unit='s').dt.year\n",
    "date.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide to drop timestamp for now because only year 2000\n",
    "\n",
    "movie_ratings = movie_ratings.drop('timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test set\n",
    "\n",
    "(training, test) = movie_ratings.randomSplit([.8, .2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ALS instance and fit model\n",
    "\n",
    "als = ALS(maxIter=10,\n",
    "          rank=10,\n",
    "          userCol='user_id',\n",
    "          itemCol='movie_id',\n",
    "          ratingCol='rating',\n",
    "          seed=42)\n",
    "\n",
    "model = als.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[movie_id: bigint, rating: bigint, user_id: bigint, prediction: float]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate predictions\n",
    "\n",
    "predictions = model.transform(test)\n",
    "predictions.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to pandas dataframe\n",
    "pred_df = predictions.select('*').toPandas()\n",
    "\n",
    "# Check nulls\n",
    "print(pred_df['prediction'].isna().sum())\n",
    "\n",
    "# Fill-in functions to give user average that was used before coldstart function complete\n",
    "def user_average(user, df):\n",
    "    \"\"\"Return average score for user\"\"\"\n",
    "    user_df = df[df['user_id'] == user]\n",
    "    average = user_df['prediction'].mean()\n",
    "    if np.isnan(average):\n",
    "        return 3\n",
    "    else:\n",
    "        return average\n",
    "    \n",
    "def compute_user_average_if_null(row):\n",
    "    \"\"\"Check if value is null, if so, replace with user average\"\"\"\n",
    "    if np.isnan(row['prediction']):\n",
    "        return user_average(row['user_id'], pred_df)\n",
    "    else:\n",
    "        return row['prediction']\n",
    "    \n",
    "# Make pandas dataframes from csv files used for coldstart function\n",
    "user_df = pd.read_csv('data/user_cluster.csv', index_col=0) \n",
    "u_clusters = pd.read_csv('data/u_info.csv', index_col=0)\n",
    "ratings_df = pd.read_csv('data/movie_cluster_avg.csv', index_col=0)\n",
    "\n",
    "# Print remaining nulls\n",
    "print(pred_df['prediction'].isna().sum())\n",
    "\n",
    "# Fill nulls with using coldstart function\n",
    "for i, row in pred_df[pred_df['prediction'].isna()].iterrows():\n",
    "    pred_df.loc[i, 'prediction'] = get_cold_start_rating(row['user_id']\n",
    "                                                         , row['movie_id']\n",
    "                                                         , user_df\n",
    "                                                         , u_clusters\n",
    "                                                         , ratings_df\n",
    "                                                        )\n",
    "\n",
    "# Check that all nulls are gone\n",
    "print(pred_df['prediction'].isna().any())\n",
    "    \n",
    "# Convert back to spark dataframe\n",
    "predictions = spark.createDataFrame(pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8772095007527893\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model \n",
    "evaluator = RegressionEvaluator(metricName='rmse', labelCol='rating',\n",
    "                               predictionCol='prediction')\n",
    "\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a parameter grid\n",
    "params = (ParamGridBuilder()\n",
    "          .addGrid(als.regParam, [1, 0.01, 0.001, 0.1])\n",
    "          .addGrid(als.maxIter, [5, 10, 20])\n",
    "          .addGrid(als.rank, [4, 10, 50])).build()\n",
    "\n",
    "# Cross validate for best hyperparameters\n",
    "cv = CrossValidator(estimator=als, estimatorParamMaps=params, evaluator=evaluator, parallelism=4)\n",
    "\n",
    "# Fit and store model\n",
    "best_model = cv.fit(movie_ratings)\n",
    "als_model = best_model.bestModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Model to Predict Ratings From Requests Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load requests json file into a spark dataframe\n",
    "requests = spark.read.json(\"data/requests.json\") \n",
    "\n",
    "# Predict requests with best ALS model and convert to Pandas dataframe\n",
    "requests_predictions = model.transform(requests).toPandas()\n",
    "\n",
    "# Print remaining nulls\n",
    "print(requests_predictions['prediction'].isna().any())\n",
    "\n",
    "# Predict null predictions with coldstart model\n",
    "for i, row in requests_predictions[requests_predictions['prediction'].isna()].iterrows():\n",
    "    requests_predictions.loc[i, 'prediction'] = get_cold_start_rating(row['user_id'], row['movie_id']\n",
    "                                                                     ,user_df\n",
    "                                                                     ,u_clusters\n",
    "                                                                     ,ratings_df)\n",
    "\n",
    "# Print remaining nulls\n",
    "print(requests_predictions['prediction'].isna().any())\n",
    "\n",
    "# Fill remaining nulls with rating of 3\n",
    "requests_predictions.loc[requests_predictions['prediction'].isna(), ['prediction']] = 3\n",
    "\n",
    "# Check that no nulls remain\n",
    "print(requests_predictions['prediction'].isna().any())\n",
    "\n",
    "# Export request predictions to dataframe to json file\n",
    "cols = ['user_id','movie_id', 'rating', 'timestamp', 'prediction']\n",
    "requests_predictions = requests_predictions[cols]\n",
    "requests_predictions.to_json(r\"data/predictions.json\"\n",
    "                                           ,orient='records'\n",
    "                                           ,lines=True\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Top 10 User Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendation_for_user(user_id):\n",
    "    \"\"\"Return top ten user recommendations\"\"\"\n",
    "    \n",
    "    import json\n",
    "    with open(\"data/predictions.json\", \"r\") as r:\n",
    "    data = []\n",
    "    for i in r:\n",
    "        data.append(json.loads(i)) \n",
    "    \n",
    "    recommendation_list = []\n",
    "    \n",
    "    for i in data:\n",
    "        if i['user_id'] == user_id:\n",
    "            recommendation_list.append({'movie_id': i['movie_id'], 'rating': i['prediction']})\n",
    "    print(recommendation_list)\n",
    "\n",
    "    sorted_list = sorted(recommendation_list, key=lambda k: k['rating'], reverse=True) \n",
    "    return sorted_list[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
