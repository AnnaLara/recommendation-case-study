{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS, ALSModel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "#from cold_start import get_cold_start_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a SparkSession object\n",
    "\n",
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .appName(\"MoviesALS\")\n",
    "         .config(\"spark.driver.host\", \"localhost\")\n",
    "         .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ratings json file into spark dataframe\n",
    "\n",
    "movie_ratings = spark.read.json('data/ratings.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movie_id: long (nullable = true)\n",
      " |-- rating: long (nullable = true)\n",
      " |-- timestamp: double (nullable = true)\n",
      " |-- user_id: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check schema\n",
    "movie_ratings.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 719949 entries, 0 to 719948\n",
      "Data columns (total 4 columns):\n",
      "movie_id     719949 non-null int64\n",
      "rating       719949 non-null int64\n",
      "timestamp    719949 non-null float64\n",
      "user_id      719949 non-null int64\n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 22.0 MB\n"
     ]
    }
   ],
   "source": [
    "# cast to Pandas dataframe to turn timestamp data to datetime and check nulls. \n",
    "\n",
    "movies_df = movie_ratings.select('*').toPandas()\n",
    "movies_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000    719949\n",
       "Name: timestamp, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attempt to change timestamp object to years, all years are 2000\n",
    "\n",
    "date = pd.to_datetime(movies_df['timestamp'], unit='s').dt.year\n",
    "date.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide to drop timestamp for now because only year 2000\n",
    "\n",
    "movie_ratings = movie_ratings.drop('timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test set\n",
    "\n",
    "(training, test) = movie_ratings.randomSplit([.8, .2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ALS instance and fit model\n",
    "\n",
    "als = ALS(maxIter=10,\n",
    "          rank=10,\n",
    "          userCol='user_id',\n",
    "          itemCol='movie_id',\n",
    "          ratingCol='rating',\n",
    "          seed=42)\n",
    "\n",
    "model = als.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[movie_id: bigint, rating: bigint, user_id: bigint, prediction: float]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate Predictions\n",
    "\n",
    "predictions = model.transform(test)\n",
    "predictions.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to pandas dataframe, fill prediction nulls, and convert back to spark dataframe\n",
    "\n",
    "pred_df = predictions.select('*').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movie_id       0\n",
       "rating         0\n",
       "user_id        0\n",
       "prediction    41\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_average(user, df):\n",
    "    \"\"\"Return average score for user\"\"\"\n",
    "    user_df = df[df['user_id'] == user]\n",
    "    average = user_df['prediction'].mean()\n",
    "    if np.isnan(average):\n",
    "        return 3\n",
    "    else:\n",
    "        return average\n",
    "    \n",
    "def compute_user_average_if_null(row):\n",
    "    \"\"\"Check if value is null, if so, replace with user average\"\"\"\n",
    "    if np.isnan(row['prediction']):\n",
    "        return user_average(row['user_id'], pred_df)\n",
    "    else:\n",
    "        return row['prediction']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = pd.read_csv('data/user_cluster.csv', index_col=0) \n",
    "u_info = pd.read_csv('data/u_info.csv', index_col=0)\n",
    "cluster_df = pd.read_csv('data/movie_cluster_avg.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(719949, 6040, 25112)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ratings_df), len(u_info), len(cluster_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in pred_df[pred_df['prediction'].isna()].iterrows():\n",
    "    pred_df.at[i, 'prediction'] = get_cold_start_rating(row['user_id'], row['movie_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(pred_df['prediction'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = spark.createDataFrame(pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model \n",
    "evaluator = RegressionEvaluator(metricName='rmse', labelCol='rating',\n",
    "                               predictionCol='prediction')\n",
    "\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a parameter grid, cross validate for best model with different hyperperameters\n",
    "params_score = {}\n",
    "\n",
    "params = (ParamGridBuilder()\n",
    "          .addGrid(als.regParam, [1, 0.01, 0.001, 0.1])\n",
    "          .addGrid(als.maxIter, [5, 10, 20])\n",
    "          .addGrid(als.rank, [4, 10, 50])).build()\n",
    "\n",
    "cv = CrossValidator(estimator=als, estimatorParamMaps=params, evaluator=evaluator, parallelism=4)\n",
    "\n",
    "best_model = cv.fit(movie_ratings)\n",
    "als_model = best_model.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "als_model.save('als_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requests loaded!\n",
      "ALS predictions made!\n"
     ]
    }
   ],
   "source": [
    "# load requests json file into a spark dataframe\n",
    "requests = spark.read.json(\"data/requests.json\") \n",
    "print(\"Requests loaded!\")\n",
    "# predict requests with als model\n",
    "requests_predictions = model.transform(requests).toPandas()\n",
    "print(\"ALS predictions made!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans values filled in!\n"
     ]
    }
   ],
   "source": [
    "# predict null predictions with cold start model\n",
    "for i, row in requests_predictions[requests_predictions['prediction'].isna()].iterrows():\n",
    "    requests_predictions.loc[i, 'prediction'] = get_cold_start_rating(row['user_id'], row['movie_id'])\n",
    "print(\"KMeans values filled in!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(requests_predictions[requests_predictions['prediction'].isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export request predictions dataframe as json file.\n",
    "predictions = requests_predictions.to_json(r\"data/predictions.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
